%------------------------------------------------------------------------------
% Beginning of journal.tex
%------------------------------------------------------------------------------
%
% AMS-LaTeX version 2 sample file for journals, based on amsart.cls.
%
%        ***     DO NOT USE THIS FILE AS A STARTER.      ***
%        ***  USE THE JOURNAL-SPECIFIC *.TEMPLATE FILE.  ***
%
% Replace amsart by the documentclass for the target journal, e.g., tran-l.
%
\documentclass{amsart}

%     If your article includes graphics, uncomment this command.
\usepackage{graphicx}
% move author affiliations around
\usepackage{amsaddr}
\usepackage{amsfonts}
\usepackage{amsmath}% 
\usepackage{calc}%     needed for the width/height calculations
%resume enumerations
\usepackage{enumitem}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{xca}[theorem]{Exercise}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\numberwithin{equation}{section}

%    Absolute value notation
\newcommand{\abs}[1]{\lvert#1\rvert}

%    Blank box placeholder for figures (to avoid requiring any
%    particular graphics capabilities for printing this document).
\newcommand{\blankbox}[2]{%
  \parbox{\columnwidth}{\centering
%    Set fboxsep to 0 so that the actual size of the box will match the
%    given measurements more closely.
    \setlength{\fboxsep}{0pt}%
    \fbox{\raisebox{0pt}[#2]{\hspace{#1}}}%
  }%
}

% Variable definitions
\def\T{$\mathcal{T}$}
\def\C{$\mathcal{C}$}
\def\TSolver{$\mathcal{T}$-\emph{solver}}
\def\sat{\texttt{SAT}}
\def\unsat{\texttt{UNSAT}}
\def\BC{\sf BC \rm}
\def\IC{\sf IC \rm}
% \newcommand{\eqdef}{\overset{\mathrm{def}}{=\joinrel=}}


% \newcommand*{\MyDef}{\mathrm{def}}
% \newcommand*{\eqdefU}{\ensuremath{\mathop{\overset{\MyDef}{=}}}}% Unscaled version
% \newcommand*{\eqdef}{\mathop{\overset{\MyDef}{\resizebox{\widthof{\eqdefU}}{\heightof{=}}{=}}}}

\newcommand\eqdef{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily def}}}{=}}}


\begin{document}

  \title[Satisfiability Modulo the Theory of Costs]{Satisfiability Modulo the Theory of Costs: Foundations and Applications}

  %    Information for first author
  \author{Marty Pye}
  \address{RWTH Aachen University}
  \email[Marty Pye]{marty.pye@rwth-aachen.de}

  \begin{abstract}
    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Etiam diam sapien, egestas at velit in, tempor malesuada turpis. Aenean eget rutrum sapien. Proin a blandit justo. Nulla fermentum placerat lacus eu tempus. Quisque nec orci eros. Nullam tempor ut lectus elementum blandit. In sed velit quis massa viverra pellentesque. Donec bibendum nibh molestie, volutpat lectus sed, eleifend nibh. Donec nec tellus justo. Vestibulum nec massa ac sapien porta ultrices.

    Mauris non consectetur quam. Suspendisse in orci consectetur, dictum erat nec, varius ante. Vivamus porta purus eget dictum dictum. Vivamus quis sem risus. Donec dictum tortor et odio tincidunt, non tincidunt nunc venenatis. Fusce nec lacus vel odio semper venenatis a sodales elit. Morbi tincidunt sit amet eros sed pharetra. Pellentesque varius pharetra ultrices. Pellentesque quam diam, blandit vel gravida in, vestibulum vel sapien. Quisque quam nibh, accumsan nec est placerat, eleifend vestibulum nulla. Cras a dapibus sapien, vel consequat urna. Cras bibendum fringilla mi dapibus tincidunt. Ut suscipit elit et risus porta, faucibus blandit ligula aliquet.
  \end{abstract}

  \maketitle

  \section{Introduction}
  \section{SMT Solving}
    The \emph{Satisfiability Modulo Theories} (SMT($\mathcal{T}$)) problem is a decision problem for logic formulas under the background of a Theory $\mathcal{T}$, and can be seen as a constraint satisfaction problem.
    A tool able to decide the satisfiability of sets of ground atomic formulas and their negations is referred to as a $\mathcal{T}$-\emph{solver}.
    If the input set of \T{}-literals $\mu$ is satisfiable under \T{}, then the \TSolver{} returns \sat{}.
    Additionally, the \TSolver{} can return a so-called \T{}-deduction clause. This can be used in early pruning, where the \T{}-deduction clause can be used in backjumping and learning.
    If the input set of \T{}-literals is not satisfiable under \T{}, then the \TSolver{} returns \unsat{} and the conflict clause consisting of the subset of \T{}-literals in $\mu$ which was found \T{}-unsatisfiable.

    A tool which is able to solve an SMT($\mathcal{T}$) problem is further referred to as an SMT($\mathcal{T}$)-solver.
    In a lazy SMT(\T{})-solver, the truth assignments for $\varphi$ are checked for \T{}-satisfiability.
    Usually, this is performed by a modified version of the DPLL algorithm.
    If a truth assignment $\mu$ is found where $\mu \models \varphi$, then $\mu$ is passed on to the \TSolver{}.
    If the \TSolver{} then returns \sat{}, the SMT(\T{})-solver found a solution.
    If not, then the \TSolver{} passes the \T{}-conflict clause $\neg\eta$ back to the learning mechanism of the DPLL algorithm. For more information on how lazy SMT(\T{}) solving works, please refer to \cite{Sebastiani07}.

  \section{Satisfiability Modulo the Theory of Costs}
    Cimatti et al.\ extend the SMT framework by adding a possibility of modelling cost functions \cite{Cimatti10}.
    An SMT(\T{}) \emph{cost problem} is a pair $\langle \varphi, costs \rangle$, where $costs \eqdef \{cost^{i}\}^{M}_{i=1}$.
    $\varphi$ is a boolean formula over ground \T{}-atoms and atoms of the form ($cost^{i} \leq c$), $c$ being some integer value.

    In the array $costs$, each $cost^{i}$ is a boolean cost function in the form
    \begin{equation}
      \label{eq:costsGeneral}
    	cost^{i} = \sum\limits_{j=1}^{N_{i}} ite(\psi^{i}_{j},c^{i}_{j1},c^{i}_{j2})
    \end{equation}
    where $ite$ (if-then-else) is a function defined as
    \[
      ite(A,c_{1},c_{2}) = 
    	\begin{cases}
        c_{1},& \text{if } A = 1 \\
        c_{2},& \text{otherwise}
    	\end{cases}
    \]
    and $\psi_{j}^{i}$ is a formula in \T{}. From here onwards, problems $\langle \varphi, costs \rangle$ are restricted s.t.
    \begin{equation}
    \label{eq:costsRestricted}
    	cost^{i} = \sum\limits_{j=1}^{N_{i}} ite(A^{i}_{j},c^{i}_{j},0)
    \end{equation}
    where $A_{j}^{i}$ is a boolean literal and $0 < c^{i}_{j} \leq c^{i}_{j+1}$.
    Passing from ~\eqref{eq:costsGeneral} to ~\eqref{eq:costsRestricted} is straightforward and possible in linear time. (SHOULD I ADD THE PROOF HERE?)

    At this point it is important to note that ~\eqref{eq:costsRestricted} can be encoded in the theory of linear arithmetic over integers ($\mathcal{LA}(\mathbb{Z})$) and therefore any $\langle \varphi, costs \rangle$ problem into the following ground \T{}$\cup \mathcal{LA}(\mathbb{Z})$-formula.
    \begin{equation}
    	\label{eq:encodingSMTIntoLA}
    	\langle \varphi, costs \rangle \equiv \varphi \bigwedge\limits_{i=1}^{M}\left(\left(c^{i} = \sum\limits_{j=1}^{N_{i}}c_{ij}\right) \land \bigwedge\limits_{j=1}^{N_{i}}\left(\left(A^{i}_{j} \to c_{ij} = c^{i}_{j}\right) \land \left(\neg A^{i}_{j} \to c_{ij} = 0\right)\right)\right)
    \end{equation}
    This could then be solved by a linear arithmetic solver, such as \cite{dutertre06}, but this is extremely inefficient. The following theory of costs is more efficient to solve.

  \section{A Theory of Costs}
    Cimatti et al.\ introduced a theory of costs $\mathcal{C}$, which allows for modelling multiple problems with $\mathcal{T} \cup \mathcal{C}$-formulas.
    \C{} is built up as follows:
    \begin{itemize}
      \item A set of $M$ variables $c^1,\ldots,c^M$. These are the output of the boolean cost functions $cost^1,\ldots,cost^M$.
      \item A binary predicate \sf BC \rm (``bound cost'') s.t.\ $\BC{}(c^i,c) \eqdef (c^i \leq c)$ with $c^i$ being a cost variable and $c$ being an integer value.
      \item A ternary predicate \IC{} (``incur cost'') s.t. $\IC{}(c^i,j,c^{i}_{j}) \eqdef c^{i}_{j}$ is added to $c^i$ as $j^{th}$ element in the sum ~\eqref{eq:costsRestricted}.
    \end{itemize}

    \begin{figure}[!t]
      \centering
      \includegraphics[width = 0.8\textwidth]{images/roverField.pdf}
      \caption{Example of an autonomous rover, which can move left, right, up and down on this $4 \times 4$ field. A move from one square to a neighbouring square costs $20$ mAh of battery.}
      \label{fig:roverField}
    \end{figure}

    This theory of costs allows for modelling domains which involve multiple costs $c^i$ and their constraints.
    At this point, we would like to introduce an example of an autonomous rover.
    Imagine a rover that can move around a $4\times4$ field of squares (Fig.\ \ref{fig:roverField}).
    A move from one square to a neighbouring square costs $20$ mAh.
    Now, we want to model this behaviour in boolean logic, so first we define some new boolean predicates:

    \begin{align*}
      \operatorname{\sf p \rm}(x,y,t) &\eqdef \text{At time point $t$, rover is at }(x,y) \\
      \operatorname{\sf move \rm}(x,y,x',y',t) &\eqdef \text{At time point $t$, rover moves from $(x,y)$ to $(x',y')$} \\
      \operatorname{\sf nextTo \rm}(x,y,x',y') &\eqdef (x,y) \text{ is next to $(x',y')$}
    \end{align*}
    \\
    Second, we define some formulas which model the behaviour of the rover:
    \begin{itemize}
      \item At every point in time, the rover is somewhere on the field:
      \begin{equation*}
        \varphi_{position} \eqdef \bigwedge\limits_{t \in \{0,\ldots,n\}} \left(\bigvee\limits_{x,y \in \{0,\ldots,3\}} \operatorname{\sf p \rm}\left(x,y,t\right)\right)
      \end{equation*}

      \item At every point in time, the rover is max.\ on one square:
      \begin{equation*}
        \varphi_{noSplitPos} \eqdef \bigwedge_{\substack{t \in \{0,\ldots,n\} \\ x,y \in \{0,\ldots,3\}}} \left(\operatorname{\sf p \rm}\left(x,y,t\right) \rightarrow \bigwedge_{\substack{x',y' \in \{0,\ldots,3\} \\ x' \neq x \wedge y' \neq y}} \neg \operatorname{\sf p \rm}\left(x',y',t\right)\right)
      \end{equation*}

      \item Between two time points, the rover either moves or stays on its current square:
      \begin{equation*}
        \varphi_{move} \eqdef \bigwedge_{\substack{t \in \{0,\ldots,n-1\} \\ x,y,x',y' \in \{0,\ldots,3\} \\ x' \neq x \lor y' \neq y}} \left( \operatorname{\sf p \rm}\left(x,y,t\right) \land \operatorname{\sf p \rm}\left(x',y',t+1\right) \rightarrow \operatorname{\sf move \rm}\left(x,y,x',y',t\right)\right) 
      \end{equation*}

      \item The rover can only move to neighbouring field, i.e.\ neither jump nor move diagonally:
      \begin{equation*}
        \varphi_{validMove} \eqdef \bigwedge_{\substack{t \in \{0,\ldots,n-1\} \\ x,y,x',y' \in \{0,\ldots,3\}}} \left(\operatorname{\sf move \rm}\left(x,y,x',y',t\right) \rightarrow \operatorname{\sf nextTo \rm}\left(x,y,x',y'\right)\right)
      \end{equation*}

      \item Moving one square costs $20$ mAh of energy:
      \begin{equation*}
        \varphi_{batteryCost} \eqdef \bigwedge_{\substack{t \in \{0,\ldots,n-1\} \\ x,y,x',y' \in \{0,\ldots,3\}}} \left(\operatorname{\sf move \rm}\left(x,y,x',y',t\right) \rightarrow \operatorname{\sf IC \rm}\left(battery,t,20\right)\right)
      \end{equation*}
    \\
    \end{itemize}
    Using this example, we can model different constraints, which we want to impose. For example, can the rover move from $(0,0)$ to $(3,2)$ in 5 steps, while not using more than $100$ mAh of battery? This can be expressed with the following formula:
    \begin{equation*}
      \begin{split}
        \varphi_{ex1} \eqdef \varphi_{position} &\land \varphi_{noSplitPos} \land \varphi_{move} \land \varphi_{validMove} \land \varphi_{batteryCost} \\ 
        &\land \operatorname{\sf p \rm}(0,0,0) \land \operatorname{\sf p \rm}(3,2,5) \land \operatorname{\sf BC \rm}(battery, 100)
      \end{split}
    \end{equation*}

    It is fairly intuitive that the above formula is satisfiable, one possible solution being the path depicted in figure \ref{fig:roverField}. However, the problem could be extended to be more complex, e.g.\ with different battery costs for each square on a $1000 \times 1000$ field, which would make the problem a lot less easier for a human to solve. Therefore, Cimatti et al.\ introduced a general decision procedure for the theory of costs, a so-called \C{}-solver. The following chapter introduces the \C{}-solver, and explains the use of the individual steps with the aid of the rover example.

  \section{\C{}-solver: A theory of costs solver}
    A \C{}-solver receives a truth assignment $\mu \eqdef \mu_{\mathcal{B}} \cup \mu_{\mathcal{T}} \cup \mu_{\mathcal{C}}$, but only selects the \C{}-relevant part. $\mu_{\mathcal{B}}$ is a set of boolean literals, $\mu_{\mathcal{T}}$ a set of \T{}-literals and $\mu_{\mathcal{C}} \eqdef \bigcup_{i=1}^M \mu_{\mathcal{C}}^i$ is a set of \C{}-literals, s.t.\ for every $i$:
    \begin{equation*}
      \begin{split}
        \mu_{\mathcal{C}^i} \eqdef \{&\operatorname{\sf BC \rm}(c^i,\operatorname{\sf ub \rm}_{(k)}^{i})\ |\ k \in \{1,...,K_i\}\} \cup \{\neg \operatorname{\sf BC \rm}(c^i,\operatorname{\sf lb \rm}_{(m)}^{i} - 1)\ |\ m \in \{1,...,M_i\}\} \\
        \cup \ \{&\operatorname{\sf IC \rm}(c^i,j,c^i_j)\ |\ j \in J^{i+}\} \cup \{\neg \operatorname{\sf IC \rm}(c^i,j,c^i_j)\ |\ j \in J^{i-}\}
      \end{split}       
    \end{equation*}
    where $\operatorname{\sf ub \rm}_{(1)}^{i},\ldots,\operatorname{\sf ub \rm}_{(K^i)}^{i}$ and $\operatorname{\sf lb \rm}_{(1)}^{i},\ldots,\operatorname{\sf lb \rm}_{(K^i)}^{i}$ are positive integer upper and lower bounds respectively. $J^{i+}$ and $J^{i-}$ are sets of indices s.t.\ $J^{i+} \cap J^{i-} = \emptyset$ and $J^{i+} \cup J^{i-} \subseteq \{1,\ldots,N_i\}$. Additionally let
    \begin{equation*}
      \begin{split}
        \operatorname{\sf lb \rm}_{max}^i &\eqdef \operatorname{\sf max \rm}(\operatorname{\sf lb \rm}_{(1)}^i,\ldots,\operatorname{\sf lb \rm}_{(M_i)}^i) \\
        \operatorname{\sf ub \rm}_{min}^i &\eqdef \operatorname{\sf min \rm}(\operatorname{\sf ub \rm}_{(1)}^i,\ldots,\operatorname{\sf ub \rm}_{(K_i)}^i) \\
        \operatorname{\sf CostOf_i \rm}(\mu) &\eqdef \sum\limits_{j \in J^{i+}}c^i_j \\
        \operatorname{\sf MCostOf_i \rm}(\mu) &\eqdef \sum\limits_{j=1}^{N_i}c^i_j - \sum\limits_{j \in J^{i-}} c^i_j  
      \end{split}
    \end{equation*}
    So the \C{}-solver takes the \C{}-relevant part $\mu_{\mathcal{C}} \eqdef \bigcup_{i=1}^M \mu_{\mathcal{C}}^i$ and for every $i$, checks whether $\mu^{i}_{\mathcal{C}}$ is \C{}-satisfiable. This is performed by the following algorithm:


    \begin{enumerate}
      \item If $\operatorname{\sf lb \rm}_{max}^i > \operatorname{\sf ub \rm}_{min}^i$ then return \unsat{} and the \C{}-conflict clause
      \begin{equation*}
        \operatorname{\sf BC \rm}(c^i, \operatorname{\sf lb \rm}_{max}^i - 1) \vee \neg \operatorname{\sf BC \rm}(c^i, \operatorname{\sf ub \rm}_{min}^i)
      \end{equation*} \\

      \item If $\operatorname{\sf CostOf_i \rm}(\mu_{\mathcal{C}}^i) > \operatorname{\sf ub \rm}_{min}^i$ then return \unsat{} and the \C{}-conflict clause
      \begin{equation*}
        \neg \operatorname{\sf BC \rm}(c^i, \operatorname{\sf ub \rm}_{min}^i) \vee \bigvee\limits_{j \in K^{i+}} \neg \operatorname{\sf IC \rm}(c^i, j, c^i_j)
      \end{equation*}
      $K^{i+}$ being a minimal subset of $J^{i+}$ s.t.\ $\sum\limits_{j \in K^{i+}} c^i_j > \operatorname{\sf ub \rm}_{min}^i$. \\\\

      \item If $\operatorname{\sf MCostOf_i \rm}(\mu_{\mathcal{C}}^i) < \operatorname{\sf lb \rm}_{max}^i$ then return \unsat{} and the \C{}-conflict clause
      \begin{equation*}
        \operatorname{\sf BC \rm}(c^i, \operatorname{\sf lb \rm}_{max}^i - 1) \vee \bigvee\limits_{j \in K^{i-}} \operatorname{\sf IC \rm}(c^i, j, c^i_j)
      \end{equation*}
      $K^{i-}$ being a minimal subset of $J^{i-}$ s.t.\ $\sum\limits_{j \in K^{i-}} c^i_j < \operatorname{\sf lb \rm}_{max}^i$. \\\\

    \end{enumerate}
    If none of the conditions $(1)$, $(2)$ or $(3)$ are fulfilled, then the \C{}-solver returns \sat{} and $\operatorname{\sf CostOf_i \rm}(\mu_{\mathcal{C}}^i)$ for every i. Also, the \C{}-solver can perform theory propagation as follows:
    \begin{enumerate}[resume]
      \item Every unassigned literal $\operatorname{\sf BC \rm}(c^i, \operatorname{\sf ub \rm}_{(r)}^i)$ with $\operatorname{\sf ub \rm}_{(r)}^i) \geq \operatorname{\sf ub \rm}_{min}^i)$ and every unassigned literal $\neg \operatorname{\sf BC \rm}(c^i, \operatorname{\sf lb \rm}_{(s)}^i - 1)$ with $\operatorname{\sf ub \rm}_{(s)}^i) \leq \operatorname{\sf lb \rm}_{max}^i)$ can be \C{}-deduced, i.e.\ added to the truth assignment:
      \begin{equation*}
        \begin{split}
          \mu_{\mathcal{C}}^i &\cup \{\operatorname{\sf BC \rm}(c^i, \operatorname{\sf ub \rm}_{(r)}^i)\} \\
          \mu_{\mathcal{C}}^i &\cup \{\neg \operatorname{\sf BC \rm}(c^i, \operatorname{\sf lb \rm}_{(s)}^{i} - 1)\}
        \end{split}
      \end{equation*}
      \item If $\operatorname{\sf CostOf_i \rm}(\mu) \leq \operatorname{\sf ub \rm}_{min}^i$ but $\left(\mu_{\mathcal{C}^i} \cup \{\operatorname{\sf IC \rm}(c^i, j, c^i_j)\}\right) > \operatorname{\sf ub \rm}_{min}^i$ for any $j \not\in (J^{i+} \cup J^{i-})$, then $\neg \operatorname{\sf IC \rm}(c^i, j, c^i_j)$ can be \C{}-deduced and added to the truth assignment: $\mu_{\mathcal{C}}^i \cup \{\operatorname{\sf IC \rm}(c^i, j, c^i_j)\}$.
      \item If $\operatorname{\sf MCostOf_i \rm}(\mu) \geq \operatorname{\sf lb \rm}_{max}^i)$ but $\left(\mu_{\mathcal{C}^i} \cup \{\neg \operatorname{\sf IC \rm}(c^i, j, c^i_j)\}\right) < \operatorname{\sf lb \rm}_{max}^i$ for any $j \not\in (J^{i+} \cup J^{i-})$, then $\operatorname{\sf IC \rm}(c^i, j, c^i_j)$ can be \C{}-deduced and added to the truth assignment: $\mu_{\mathcal{C}}^i \cup \{\neg \operatorname{\sf IC \rm}(c^i, j, c^i_j)\}$.
    \end{enumerate}

    In the following paragraphs, the individual steps of the \C{}-solver are explained with regards to the autonomous rover example described above. \\

    Step (1) is pretty straight forward. If the highest lower bound is larger than the lowest upper bound for a certain cost, then obviously, the formula is not satisfiable. In the rover example, this would be the case for e.g.\ $\varphi_{ex1} \land \neg \operatorname{\sf BC \rm}(battery,110)$. The rover can't simultaneously use at least $110$ mAh and at most $100$ mAh of battery. This is precisely what the conflict clause then expresses. \\

    Step (2) describes that for the current truth assignment, the accumulated cost for one cost variable may not exceed the lowest upper bound. In $\varphi_{ex1}$ for example, the solver checks wether all the currently incurred costs ($20$ mAh for each step) sum up to more than $100$. If yes, then the solver specifies that either the lowest upper bound cannot be $100$, or at one of the previous steps, the rover wasn't allowed to incur the costs it did. \\

    Step (3) is analogous to step (2), just for the highest lower bound, i.e.\ the maximal accumulatable cost for the current assignment must exceed the highest lower bound, otherwise the formula is not satisfiable. \\

    Step (4) is relevant for early pruning. An important feature of this solver is that it can also take partial truth assignments. In order to show how this step can be useful, we have to complicate the $\varphi_{ex1}$ example a bit. Let's assume we have the formula 
    \begin{equation*}
      \varphi_{ex1} \land (\psi_1 \lor \operatorname{\sf BC \rm}(battery, 80) \lor \psi_2)
    \end{equation*}
    and the SAT-solver has already decided that $\psi_1$ and $\psi_2$ need to be false. Therefore $\operatorname{\sf BC \rm}(battery, 80)$ has to be true, and the solver can deduce that the unassigned literal $\operatorname{\sf BC \rm}(battery, 100)$ is automatically also true, and is then added to the truth assignment (\C{}-propagated). This makes the solving process more efficient. \\

    Step (5) and (6) basically do the same thing for upper and lower bound respectively. Assuming the SAT solver has currently chosen an assignment which makes the rover move down from $(0,0)$ all the way to the corner, and then right until $(2,3)$. At this point in time, $\operatorname{\sf CostOf_i \rm}(\mu)$ is still $100$, but the cost incurred for the next step exceeds the $100$ bound. Therefore, the solver can deduce and propagate that this cost may not be incurred. The SAT-solver will then deduce that due to $\varphi_{batteryCost}$, the rover may not make that move, and has to find a different path.
   
  \bibliographystyle{amsplain}
  \bibliography{references}

\end{document}

%------------------------------------------------------------------------------
% End of journal.tex
%------------------------------------------------------------------------------
